// Mock LLM Service for PocketFlow Hello World
// Mimics the Python call_llm.py functionality
import Debug "mo:base/Debug";
import Text "mo:base/Text";
import Time "mo:base/Time";
import Random "mo:base/Random";
import Blob "mo:base/Blob";
import Array "mo:base/Array";

actor LLMMockService {
    
    // Mock responses based on common question patterns
    private let mockResponses = [
        ("meaning of life", "42 is the answer to the ultimate question of life, the universe, and everything."),
        ("end of universe", "The universe will eventually reach maximum entropy in a state called heat death."),
        ("what is ai", "Artificial Intelligence is the simulation of human intelligence by machines."),
        ("hello", "Hello! I'm a mock LLM running on the Internet Computer."),
        ("how are you", "I'm doing great! Thanks for asking. I'm just a simple mock service."),
        ("weather", "I'm sorry, I don't have access to real weather data, but I hope it's nice where you are!"),
        ("time", "Time is a dimension that allows events to progress from past to future."),
        ("blockchain", "Blockchain is a distributed ledger technology that maintains a continuously growing list of records.")
    ];
    
    // Default response for unknown queries
    private let defaultResponse = "That's an interesting question! As a mock LLM service, I can provide thoughtful responses to help demonstrate PocketFlow workflows on the Internet Computer.";
    
    // Main LLM call function that mimics OpenAI API
    public func call_llm(prompt: Text) : async Text {
        Debug.print("LLM Mock Service called with prompt: " # prompt);
        
        // Add some artificial delay to simulate real LLM latency
        let startTime = Time.now();
        while (Time.now() - startTime < 500_000_000) { }; // 0.5 second delay
        
        // Convert prompt to lowercase for matching
        let lowerPrompt = Text.toLowercase(prompt);
        
        // Check for keyword matches
        for ((keyword, response) in mockResponses.vals()) {
            if (Text.contains(lowerPrompt, #text keyword)) {
                return response # " (Generated by IC Mock LLM at " # debug_show(Time.now()) # ")";
            };
        };
        
        // Return default response with some context
        defaultResponse # " Your question was: '" # prompt # "' (Generated by IC Mock LLM at " # debug_show(Time.now()) # ")"
    };
    
    // Health check endpoint
    public func health() : async Text {
        "LLM Mock Service is healthy and running on the Internet Computer!"
    };
    
    // Get available mock response categories
    public func get_categories() : async [Text] {
        let categories = ["meaning of life", "end of universe", "what is ai", "hello", "how are you", "weather", "time", "blockchain"];
        categories
    };
    
    // Advanced mock that can handle different "models"
    public func call_llm_with_model(prompt: Text, model: Text) : async Text {
        let modelPrefix = switch (model) {
            case ("gpt-4") { "[GPT-4 Mock] " };
            case ("gpt-3.5") { "[GPT-3.5 Mock] " };
            case ("claude") { "[Claude Mock] " };
            case (_) { "[Generic Mock] " };
        };
        
        let response = await call_llm(prompt);
        modelPrefix # response
    };
    
    // Batch processing for multiple prompts
    public func call_llm_batch(prompts: [Text]) : async [Text] {
        var responses: [Text] = [];
        for (prompt in prompts.vals()) {
            let response = await call_llm(prompt);
            responses := Array.append(responses, [response]);
        };
        responses
    };
    
    // Simple function to test the service
    public func test() : async Text {
        await call_llm("What is the meaning of life?")
    };
}